{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-26T11:42:17.796604Z","iopub.execute_input":"2021-06-26T11:42:17.796983Z","iopub.status.idle":"2021-06-26T11:42:17.809976Z","shell.execute_reply.started":"2021-06-26T11:42:17.796952Z","shell.execute_reply":"2021-06-26T11:42:17.808637Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"/kaggle/input/ieee-fraud-detection/sample_submission.csv\n/kaggle/input/ieee-fraud-detection/test_identity.csv\n/kaggle/input/ieee-fraud-detection/train_identity.csv\n/kaggle/input/ieee-fraud-detection/test_transaction.csv\n/kaggle/input/ieee-fraud-detection/train_transaction.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Extensive EDA and Modeling XGB Hyperopt","metadata":{}},{"cell_type":"markdown","source":"## Competition Ovjective is to detect fraud in transactions","metadata":{}},{"cell_type":"markdown","source":"### Data\nIn this competition you are predicting the probability that an online transaction is fradulent, as denoted by the binary target `isFraud`.\n\nThe data is broken into two files **identity** and **transaction**, which are joined by `TransactionID`.\n\n    Note: Not all transactions have corresponding identity information.\n   ","metadata":{}},{"cell_type":"markdown","source":"#### Categorical Features - Transactions\n* ProductCD\n* emaildomain\n* card1-card6\n* addr1,addr2\n* P_emaildomain\n* R_emaildomain\n* M1-M9\n\n#### Categorical Features - Identity\n* DeviceType\n* DeviceInfo\n* id_12-id_38\n\n#### The TransactionDT feature is a timedelta from a given reference datetime(not an actual timestamp).","metadata":{}},{"cell_type":"markdown","source":"# Questions\nI will start exploring based on Categorical Features and Transaction Amounts. The aim is answer some questions like:\n* What type of data we have on out data?\n* How many cols, rows, missing values we have?\n* Whats the target distribution?\n* What's the Transactions values distribution of fraud and no fraud transactions?\n* What have predominat fraudulent products?\n* What features or target shows some interestin patterns?\n* And a lot of more questions that will raise trought the exploration.","metadata":{}},{"cell_type":"markdown","source":"## Importing necessary libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport scipy as sp\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Standard plotly imports\n#import plotly.plotly as py\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nfrom plotly.offline import iplot, init_notebook_mode\n#import cufflinks\n#import cufflinks as cf\nimport plotly.figure_factory as ff\n\n# Using plotly + cufflinks in offline mode\ninit_notebook_mode(connected=True)\n#cufflinks.go_offline(connected=True)\n\n# Preprocessing, modelling and evaluating\nfrom sklearn import preprocessing\nfrom sklearn.metrics import confusion_matrix, roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score, KFold\nfrom xgboost import XGBClassifier\nimport xgboost as xgb\n\n## Hyperopt modules\nfrom hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK, STATUS_RUNNING\nfrom functools import partial\n\nimport os\nimport gc\nprint(os.listdir(\"../input\"))","metadata":{"execution":{"iopub.status.busy":"2021-06-26T11:42:19.528278Z","iopub.execute_input":"2021-06-26T11:42:19.528872Z","iopub.status.idle":"2021-06-26T11:42:19.540362Z","shell.execute_reply.started":"2021-06-26T11:42:19.528834Z","shell.execute_reply":"2021-06-26T11:42:19.539291Z"},"trusted":true},"execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}},{"name":"stdout","text":"['ieee-fraud-detection']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Importing train datasets","metadata":{}},{"cell_type":"code","source":"df_id = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\ndf_trans=pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-26T11:42:20.770060Z","iopub.execute_input":"2021-06-26T11:42:20.770418Z","iopub.status.idle":"2021-06-26T11:42:47.914796Z","shell.execute_reply.started":"2021-06-26T11:42:20.770387Z","shell.execute_reply":"2021-06-26T11:42:47.913659Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"I will set all functions in the cell below","metadata":{}},{"cell_type":"code","source":"def resumetable(df):\n    print(f\"Dataset Shape: {df.shape}\")\n    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n    summary=summary.reset_index()\n    summary[\"Name\"]=summary['index']\n    summary=summary[['Name','dtypes']]\n    summary['Missing']=df.isnull().sum().values\n    summary['Uniques']=df.nunique().values\n    summary['First Value']=df.loc[0].values\n    summary['Second Value']=df.loc[1].values\n    summary['Third Value']=df.loc[2].values\n    \n    for name in summary['Name'].value_counts().index:\n        summary.loc[summary['Name']==name,'Entropy']=round(stats.entropy(df[name].value_counts(normalize=True),base=2),2)\n        \n    return summary\n\n## Function to reduce the DF size\ndef reduce_mem_usage(df, verbose=True):\n    numerics=['int16','int32','int64','float16','float32','float64']\n    start_mem=df.memory_usage().sum()/1024**2\n    for col in df.columns:\n        col_type=df[col].dtypes\n        if col_type in numerics:\n            c_min=df[col].min()\n            c_max=df[col].max()\n            if str(col_type)[:3]=='int':\n                if c_min> np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col]=df[col].astype(np.int8)\n                elif c_min> np.iinfo(np.int16).min and c_max <np.iinfo(np.int16).max:\n                    df[col]=df[col].astype(np.int16)\n                elif c_min> np.iinfo(np.int32).min and c_max <np.iinfo(np.int32).max:\n                    df[col]=df[col].astype(np.int32)\n                elif c_min> np.iinfo(np.int64).min and c_max <np.iinfo(np.int64).max:\n                    df[col]=df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max <np.finfo(np.float16).max:\n                    df[col]=df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max <np.finfo(np.float32).max:\n                    df[col]=df[col].astype(np.float32)\n                else:\n                    df[col]=df[col].astype(np.float64)\n    end_mem=df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100*(start_mem - end_mem)/start_mem))\n    return df\n    \ndef CalcOutliers(df_num):\n    \n    # calculating mena and std of the array\n    data_mean,data_std=np.mean(df_num),np.std(df_num)\n    \n    # setting the cut line to both higher and lower values\n    #You can change this value\n    cut=data_std*3\n    \n    # Calculating the higher and lower cut values\n    lower,upper= data_mean -cut, data_mean +cut\n    \n    # creating an array of lower, higher and total outlier values\n    outliers_lower=[x for x in df_num if x< lower]\n    outliers_higher=[x for x in df_num if x>upper]\n    outliers_total=[x for x in df_num if x< lower or x>upper]\n    \n    #array without outlier values\n    outlier_removed=[x for x in df_num if x>lower and x< upper]\n    \n    print(\"Identified lowest outliers: %d\" %len(outliers_lower))\n    #printing total number of values in lower cut of outliers\n    print(\"Identified upper outliers: %d\" %len(outliers_higher))\n    #printing total number of values in higher cut of outliers\n    print(\"Total outlier observations: %d\" %len(outliers_total))\n    #printing total number of values in lower cut of both sides\n    print(\"Non-outlier oberservations: %d\" %len(outliers_removed))\n    #printing total number of non outlier values\n    print(\"Total percentual of Outliers: \",rount((len(outliers_totla)/len(outliers_removed))*100,4))\n    #Percentual of outliers in points\n    \n    return","metadata":{"execution":{"iopub.status.busy":"2021-06-26T11:51:19.163729Z","iopub.execute_input":"2021-06-26T11:51:19.164275Z","iopub.status.idle":"2021-06-26T11:51:19.197423Z","shell.execute_reply.started":"2021-06-26T11:51:19.164219Z","shell.execute_reply":"2021-06-26T11:51:19.196181Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"## Reducing memory\ndf_trans=reduce_mem_usage(df_trans)\ndf_id=reduce_mem_usage(df_id)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T11:49:27.361607Z","iopub.execute_input":"2021-06-26T11:49:27.361998Z","iopub.status.idle":"2021-06-26T11:49:33.653247Z","shell.execute_reply.started":"2021-06-26T11:49:27.361962Z","shell.execute_reply":"2021-06-26T11:49:33.651990Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Mem. usage decreased to 542.35 Mb (0.0% reduction)\nMem. usage decreased to 25.86 Mb (0.0% reduction)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Knowing the data","metadata":{"execution":{"iopub.status.busy":"2021-06-26T11:50:18.944449Z","iopub.execute_input":"2021-06-26T11:50:18.944821Z","iopub.status.idle":"2021-06-26T11:50:18.949636Z","shell.execute_reply.started":"2021-06-26T11:50:18.944790Z","shell.execute_reply":"2021-06-26T11:50:18.948199Z"}}},{"cell_type":"code","source":"resumetable(df_trans)[:25]","metadata":{"execution":{"iopub.status.busy":"2021-06-26T11:51:22.229515Z","iopub.execute_input":"2021-06-26T11:51:22.230009Z","iopub.status.idle":"2021-06-26T11:51:36.895077Z","shell.execute_reply.started":"2021-06-26T11:51:22.229965Z","shell.execute_reply":"2021-06-26T11:51:36.894021Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"Dataset Shape: (590540, 394)\n","output_type":"stream"},{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"              Name   dtypes  Missing  Uniques First Value Second Value  \\\n0    TransactionID    int32        0   590540     2987000      2987001   \n1          isFraud     int8        0        2           0            0   \n2    TransactionDT    int32        0   573349       86400        86401   \n3   TransactionAmt  float16        0     8195        68.5         29.0   \n4        ProductCD   object        0        5           W            W   \n5            card1    int16        0    13553       13926         2755   \n6            card2  float16     8933      500         NaN        404.0   \n7            card3  float16     1565      114       150.0        150.0   \n8            card4   object     1577        4    discover   mastercard   \n9            card5  float16     4259      119       142.0        102.0   \n10           card6   object     1571        4      credit       credit   \n11           addr1  float16    65706      332       315.0        325.0   \n12           addr2  float16    65706       74        87.0         87.0   \n13           dist1  float16   352271     2412        19.0          NaN   \n14           dist2  float16   552913     1699         NaN          NaN   \n15   P_emaildomain   object    94456       59         NaN    gmail.com   \n16   R_emaildomain   object   453249       60         NaN          NaN   \n17              C1  float16        0     1495         1.0          1.0   \n18              C2  float16        0     1167         1.0          1.0   \n19              C3  float16        0       27         0.0          0.0   \n20              C4  float16        0     1223         0.0          0.0   \n21              C5  float16        0      319         0.0          0.0   \n22              C6  float16        0     1291         1.0          1.0   \n23              C7  float16        0     1069         0.0          0.0   \n24              C8  float16        0     1130         0.0          0.0   \n\n    Third Value  Entropy  \n0       2987002    19.17  \n1             0     0.22  \n2         86469    19.11  \n3          59.0     8.10  \n4             W     1.28  \n5          4663     9.97  \n6         490.0     6.32  \n7         150.0     0.68  \n8          visa     1.09  \n9         166.0     2.66  \n10        debit     0.82  \n11        330.0     5.06  \n12         87.0     0.08  \n13        287.0     6.33  \n14          NaN     7.41  \n15  outlook.com     2.68  \n16          NaN     2.76  \n17          1.0     2.72  \n18          1.0     2.75  \n19          0.0     0.04  \n20          0.0     1.12  \n21          0.0     2.06  \n22          1.0     2.52  \n23          0.0     0.71  \n24          0.0     1.25  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>dtypes</th>\n      <th>Missing</th>\n      <th>Uniques</th>\n      <th>First Value</th>\n      <th>Second Value</th>\n      <th>Third Value</th>\n      <th>Entropy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TransactionID</td>\n      <td>int32</td>\n      <td>0</td>\n      <td>590540</td>\n      <td>2987000</td>\n      <td>2987001</td>\n      <td>2987002</td>\n      <td>19.17</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>isFraud</td>\n      <td>int8</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.22</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TransactionDT</td>\n      <td>int32</td>\n      <td>0</td>\n      <td>573349</td>\n      <td>86400</td>\n      <td>86401</td>\n      <td>86469</td>\n      <td>19.11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TransactionAmt</td>\n      <td>float16</td>\n      <td>0</td>\n      <td>8195</td>\n      <td>68.5</td>\n      <td>29.0</td>\n      <td>59.0</td>\n      <td>8.10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ProductCD</td>\n      <td>object</td>\n      <td>0</td>\n      <td>5</td>\n      <td>W</td>\n      <td>W</td>\n      <td>W</td>\n      <td>1.28</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>card1</td>\n      <td>int16</td>\n      <td>0</td>\n      <td>13553</td>\n      <td>13926</td>\n      <td>2755</td>\n      <td>4663</td>\n      <td>9.97</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>card2</td>\n      <td>float16</td>\n      <td>8933</td>\n      <td>500</td>\n      <td>NaN</td>\n      <td>404.0</td>\n      <td>490.0</td>\n      <td>6.32</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>card3</td>\n      <td>float16</td>\n      <td>1565</td>\n      <td>114</td>\n      <td>150.0</td>\n      <td>150.0</td>\n      <td>150.0</td>\n      <td>0.68</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>card4</td>\n      <td>object</td>\n      <td>1577</td>\n      <td>4</td>\n      <td>discover</td>\n      <td>mastercard</td>\n      <td>visa</td>\n      <td>1.09</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>card5</td>\n      <td>float16</td>\n      <td>4259</td>\n      <td>119</td>\n      <td>142.0</td>\n      <td>102.0</td>\n      <td>166.0</td>\n      <td>2.66</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>card6</td>\n      <td>object</td>\n      <td>1571</td>\n      <td>4</td>\n      <td>credit</td>\n      <td>credit</td>\n      <td>debit</td>\n      <td>0.82</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>addr1</td>\n      <td>float16</td>\n      <td>65706</td>\n      <td>332</td>\n      <td>315.0</td>\n      <td>325.0</td>\n      <td>330.0</td>\n      <td>5.06</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>addr2</td>\n      <td>float16</td>\n      <td>65706</td>\n      <td>74</td>\n      <td>87.0</td>\n      <td>87.0</td>\n      <td>87.0</td>\n      <td>0.08</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>dist1</td>\n      <td>float16</td>\n      <td>352271</td>\n      <td>2412</td>\n      <td>19.0</td>\n      <td>NaN</td>\n      <td>287.0</td>\n      <td>6.33</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>dist2</td>\n      <td>float16</td>\n      <td>552913</td>\n      <td>1699</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7.41</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>P_emaildomain</td>\n      <td>object</td>\n      <td>94456</td>\n      <td>59</td>\n      <td>NaN</td>\n      <td>gmail.com</td>\n      <td>outlook.com</td>\n      <td>2.68</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>R_emaildomain</td>\n      <td>object</td>\n      <td>453249</td>\n      <td>60</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.76</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>C1</td>\n      <td>float16</td>\n      <td>0</td>\n      <td>1495</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.72</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>C2</td>\n      <td>float16</td>\n      <td>0</td>\n      <td>1167</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.75</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>C3</td>\n      <td>float16</td>\n      <td>0</td>\n      <td>27</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>C4</td>\n      <td>float16</td>\n      <td>0</td>\n      <td>1223</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.12</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>C5</td>\n      <td>float16</td>\n      <td>0</td>\n      <td>319</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.06</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>C6</td>\n      <td>float16</td>\n      <td>0</td>\n      <td>1291</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.52</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>C7</td>\n      <td>float16</td>\n      <td>0</td>\n      <td>1069</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.71</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>C8</td>\n      <td>float16</td>\n      <td>0</td>\n      <td>1130</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Target Distribution","metadata":{}},{"cell_type":"code","source":"df_trans['TransactionAmt']=df_trans['TransactionAmt'].astype(float)\ntotal=len(df_trans)\ntotal_amt=df_trans.groupby(['isFraud'])['TransactionAmt'].sum().sum()\nplt.figure(figsize=(16,6))\n\nplt.subplot(121)\ng=sns.countplot(x='isFraud',data=df_trans,)\ng.set_title(\"Fraud Transaction Distribution \\n# 0: No Fraud | 1: Fraud #\",fontsize=22)\ng.set_xlabel(\"Is fraud?\",fontsize=18)\ng.set_ylabel(\"Count\",fontsize=18)\nfor p in g.patches:\n    height= p. get_height()\n    g.text(p.get_x()_+p.get_width()/2.,height +3, '{:1.2f}%'.format(height/total*100), ha=\"center\",fontsize=15)\nperc_amt=(df_trans.groupby([\"isfraud\"])['TransactionAmt'].sum())\nperc_amt=perc_amt.reset_index()\nplt.subplot(122)\ng1=sns.barplot(x='isFraud',y='Transaction Amt \\n# 0: No Fraud | 1: Fraud #',fontsize=22)\ng1.set_xlabel(\"Is fraud?\",fontsize=18)\ng1.set_ylabel(\"Total Transaction Amount Scalar\",fontsize=18)\nfor p in g1.patches:\n    height=p.get_height()\n    g1.text(p.get_x()+p.get_width()/2.,height+3,'{:1.2f}%'.format(height/total_amt*100),ha=\"center\",fontsize=15)\nplt.show()    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have 3.5% of Fraud transactions in out dataset.\nI think that it would be interesting to see if the amount percentual is higher or lower than 3.5% of total. I will see it later.\nWe have the same % when considering the Total Transaction Amount by Fraud and No Fraud.\nLet's explore the Transaction amount further below.","metadata":{}},{"cell_type":"markdown","source":"## Transaction Amount Quantiles\n\nBefore Ploting Transaction Amount, let's see the quantiles of Transaction Amount","metadata":{}},{"cell_type":"code","source":"df_trans['TransactionAmt']=df_trans['TransactionAmt'].astype(float)\nprint(\"Transaction Amounts Quantiles:\")\nprint(df_trans['TransactionAmt'].quantile([.01,.025,.1,.25,.5,.75,.9,.975,.99]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ploting Transaction Amount Values Distribution","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(16,12))\nplt.suptitle('Transaction Values Distribution', fontsize=22)\nplt.subplot(221)\ng = sns.distplot(df_trans[df_trans['TransactionAmt'] <= 1000]['TransactionAmt'])\ng.set_title(\"Transaction Amount Distribuition <= 1000\", fontsize=18)\ng.set_xlabel(\"\")\ng.set_ylabel(\"Probability\", fontsize=15)\n\nplt.subplot(222)\ng1 = sns.distplot(np.log(df_trans['TransactionAmt']))\ng1.set_title(\"Transaction Amount (Log) Distribuition\", fontsize=18)\ng1.set_xlabel(\"\")\ng1.set_ylabel(\"Probability\", fontsize=15)\n\nplt.figure(figsize=(16,12))\n\n\nplt.subplot(212)\ng4 = plt.scatter(range(df_trans[df_trans['isFraud'] == 0].shape[0]),\n                 np.sort(df_trans[df_trans['isFraud'] == 0]['TransactionAmt'].values), \n                 label='NoFraud', alpha=.2)\ng4 = plt.scatter(range(df_trans[df_trans['isFraud'] == 1].shape[0]),\n                 np.sort(df_trans[df_trans['isFraud'] == 1]['TransactionAmt'].values), \n                 label='Fraud', alpha=.2)\ng4= plt.title(\"ECDF \\nFRAUD and NO FRAUD Transaction Amount Distribution\", fontsize=18)\ng4 = plt.xlabel(\"Index\")\ng4 = plt.ylabel(\"Amount Distribution\", fontsize=15)\ng4 = plt.legend()\n\nplt.figure(figsize=(16,12))\n\nplt.subplot(321)\ng = plt.scatter(range(df_trans[df_trans['isFraud'] == 1].shape[0]), \n                 np.sort(df_trans[df_trans['isFraud'] == 1]['TransactionAmt'].values), \n                label='isFraud', alpha=.4)\nplt.title(\"FRAUD - Transaction Amount ECDF\", fontsize=18)\nplt.xlabel(\"Index\")\nplt.ylabel(\"Amount Distribution\", fontsize=12)\n\nplt.subplot(322)\ng1 = plt.scatter(range(df_trans[df_trans['isFraud'] == 0].shape[0]),\n                 np.sort(df_trans[df_trans['isFraud'] == 0]['TransactionAmt'].values), \n                 label='NoFraud', alpha=.2)\ng1= plt.title(\"NO FRAUD - Transaction Amount ECDF\", fontsize=18)\ng1 = plt.xlabel(\"Index\")\ng1 = plt.ylabel(\"Amount Distribution\", fontsize=15)\n\nplt.suptitle('Individual ECDF Distribution', fontsize=22)\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Seeing the Quantiles of Fraud and No Fraud Transactions","metadata":{}},{"cell_type":"code","source":"print(pd.concat([df_trans[df_trans['isFraud'] == 1]['TransactionAmt']\\\n                 .quantile([.01, .1, .25, .5, .75, .9, .99])\\\n                 .reset_index(), \n                 df_trans[df_trans['isFraud'] == 0]['TransactionAmt']\\\n                 .quantile([.01, .1, .25, .5, .75, .9, .99])\\\n                 .reset_index()],\n                axis=1, keys=['Fraud', \"No Fraud\"]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transaction Amount Outliers\n- It's considering outlier values that are highest than 3 times the std from the mean","metadata":{}},{"cell_type":"code","source":"CalcOutliers(df_trans['TransactionAmt'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If we consider only values between >= 0 to 800 we will avoid the outliers and has more confidence in our distribution. <br>\nWe have 10k rows with outliers that represents 1.74% of total rows.","metadata":{}},{"cell_type":"markdown","source":"# Now, let's known the Product Feature\n- Distribution Products\n- Distribution of Frauds by Product\n- Has Difference between Transaction Amounts in Products? ","metadata":{}},{"cell_type":"code","source":"tmp = pd.crosstab(df_trans['ProductCD'], df_trans['isFraud'], normalize='index') * 100\ntmp = tmp.reset_index()\ntmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\nplt.figure(figsize=(14,10))\nplt.suptitle('ProductCD Distributions', fontsize=22)\n\nplt.subplot(221)\ng = sns.countplot(x='ProductCD', data=df_trans)\n# plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\n\ng.set_title(\"ProductCD Distribution\", fontsize=19)\ng.set_xlabel(\"ProductCD Name\", fontsize=17)\ng.set_ylabel(\"Count\", fontsize=17)\ng.set_ylim(0,500000)\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(height/total*100),\n            ha=\"center\", fontsize=14) \n\nplt.subplot(222)\ng1 = sns.countplot(x='ProductCD', hue='isFraud', data=df_trans)\nplt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])\ngt = g1.twinx()\ngt = sns.pointplot(x='ProductCD', y='Fraud', data=tmp, color='black', order=['W', 'H',\"C\", \"S\", \"R\"], legend=False)\ngt.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n\ng1.set_title(\"Product CD by Target(isFraud)\", fontsize=19)\ng1.set_xlabel(\"ProductCD Name\", fontsize=17)\ng1.set_ylabel(\"Count\", fontsize=17)\n\nplt.subplot(212)\ng3 = sns.boxenplot(x='ProductCD', y='TransactionAmt', hue='isFraud', \n              data=df_trans[df_trans['TransactionAmt'] <= 2000] )\ng3.set_title(\"Transaction Amount Distribuition by ProductCD and Target\", fontsize=20)\ng3.set_xlabel(\"ProductCD Name\", fontsize=17)\ng3.set_ylabel(\"Transaction Values\", fontsize=17)\n\nplt.subplots_adjust(hspace = 0.6, top = 0.85)\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"W, C and R are the most frequent values. <br>\nWe can note that in W, H and R the distribution of Fraud values are slightly higher than the Non-Fraud Transactions","metadata":{}},{"cell_type":"markdown","source":"# Card Features\n- Based on Competition Description, card features are categoricals.\n- Lets understand the distribution of values\n- What's the different in transactions and % of Fraud for each values in these features\n- Card features has 6 columns, and 4 of them seems to be numericals, so lets see the quantiles and distributions","metadata":{}},{"cell_type":"code","source":"## Knowning the Card Features\nresumetable(df_trans[['card1', 'card2', 'card3','card4', 'card5', 'card6']])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Card2-Card6 has some missing values. We will need to due with it later.","metadata":{}},{"cell_type":"markdown","source":"# Numericals Feature Card Quantiles","metadata":{}},{"cell_type":"code","source":"print(\"Card Features Quantiles: \")\nprint(df_trans[['card1', 'card2', 'card3', 'card5']].quantile([0.01, .025, .1, .25, .5, .75, .975, .99]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that Card 1 and Card 2 has a large distribution of values, so maybe it will be better to get the log of these columns","metadata":{}},{"cell_type":"code","source":"\ndf_trans.loc[df_trans.card3.isin(df_trans.card3.value_counts()[df_trans.card3.value_counts() < 200].index), 'card3'] = \"Others\"\ndf_trans.loc[df_trans.card5.isin(df_trans.card5.value_counts()[df_trans.card5.value_counts() < 300].index), 'card5'] = \"Others\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing Card 1, Card 2 and Card 3 Distributions\n- As the Card 1 and 2 are numericals, I will plot the distribution of them\n- in Card 3, as we have many values with low frequencies, I decided to set value to \"Others\" \n- Also, in Card 3 I set the % of Fraud ratio in yaxis2","metadata":{}},{"cell_type":"code","source":"tmp = pd.crosstab(df_trans['card3'], df_trans['isFraud'], normalize='index') * 100\ntmp = tmp.reset_index()\ntmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\ntmp2 = pd.crosstab(df_trans['card5'], df_trans['isFraud'], normalize='index') * 100\ntmp2 = tmp2.reset_index()\ntmp2.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\nplt.figure(figsize=(14,22))\n\nplt.subplot(411)\ng = sns.distplot(df_trans[df_trans['isFraud'] == 1]['card1'], label='Fraud')\ng = sns.distplot(df_trans[df_trans['isFraud'] == 0]['card1'], label='NoFraud')\ng.legend()\ng.set_title(\"Card 1 Values Distribution by Target\", fontsize=20)\ng.set_xlabel(\"Card 1 Values\", fontsize=18)\ng.set_ylabel(\"Probability\", fontsize=18)\n\nplt.subplot(412)\ng1 = sns.distplot(df_trans[df_trans['isFraud'] == 1]['card2'].dropna(), label='Fraud')\ng1 = sns.distplot(df_trans[df_trans['isFraud'] == 0]['card2'].dropna(), label='NoFraud')\ng1.legend()\ng1.set_title(\"Card 2 Values Distribution by Target\", fontsize=20)\ng1.set_xlabel(\"Card 2 Values\", fontsize=18)\ng1.set_ylabel(\"Probability\", fontsize=18)\n\nplt.subplot(413)\ng2 = sns.countplot(x='card3', data=df_trans, order=list(tmp.card3.values))\ng22 = g2.twinx()\ngg2 = sns.pointplot(x='card3', y='Fraud', data=tmp, \n                    color='black', order=list(tmp.card3.values))\ngg2.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\ng2.set_title(\"Card 3 Values Distribution and % of Transaction Frauds\", fontsize=20)\ng2.set_xlabel(\"Card 3 Values\", fontsize=18)\ng2.set_ylabel(\"Count\", fontsize=18)\nfor p in g2.patches:\n    height = p.get_height()\n    g2.text(p.get_x()+p.get_width()/2.,\n            height + 25,\n            '{:1.2f}%'.format(height/total*100),\n            ha=\"center\") \n\nplt.subplot(414)\ng3 = sns.countplot(x='card5', data=df_trans, order=list(tmp2.card5.values))\ng3t = g3.twinx()\ng3t = sns.pointplot(x='card5', y='Fraud', data=tmp2, \n                    color='black', order=list(tmp2.card5.values))\ng3t.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\ng3.set_title(\"Card 5 Values Distribution and % of Transaction Frauds\", fontsize=20)\ng3.set_xticklabels(g3.get_xticklabels(),rotation=90)\ng3.set_xlabel(\"Card 5 Values\", fontsize=18)\ng3.set_ylabel(\"Count\", fontsize=18)\nfor p in g3.patches:\n    height = p.get_height()\n    g3.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(height/total*100),\n            ha=\"center\",fontsize=11) \n    \nplt.subplots_adjust(hspace = 0.6, top = 0.85)\n\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}